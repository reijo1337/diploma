{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-Ja7EGZG7jl"
   },
   "source": [
    "# Sign Language Recognition from Hand Gestures using Capsule Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-w-SqyIG7jm"
   },
   "source": [
    "## Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDlTk7toG7jn"
   },
   "source": [
    "1- Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
    "2- Code adapted from https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py\n",
    "Author: Xifeng Guo, E-mail: guoxifeng1990@163.com, Github: https://github.com/XifengGuo/CapsNet-Keras\n",
    "3- I benefited from the information on the following site.\n",
    "https://www.kaggle.com/kmader/capsulenet-on-mnist/\n",
    "4- The current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\n",
    "5- Adopting to other backends should be easy\n",
    "\n",
    "Result: Loss=0.04 after 5 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11077,
     "status": "ok",
     "timestamp": 1591619266937,
     "user": {
      "displayName": "Григорий Танцевов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiY72fHLg5AYXzqwOsvSwk6GbJcNY1PkFQ88acKmg=s64",
      "userId": "00673231704768357118"
     },
     "user_tz": -180
    },
    "id": "zG38VfqdG7jo",
    "outputId": "0f8be5ae-40d1-4e1d-9a7a-83d7f6505ff8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tantsevov/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fD57w8ZG7jt"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3IwQlLx5G7ju"
   },
   "source": [
    "The Sign Language MNIST dataset has images of hand gestures each representing one of the 24 alphabets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQhL43ZtG7jv"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def skin_detector(img):\n",
    "    img_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17, 170, 255))\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255, 180, 135))\n",
    "    global_mask = cv2.bitwise_and(YCrCb_mask, HSV_mask)\n",
    "    global_result = cv2.bitwise_not(global_mask)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    global_result = cv2.erode(global_result, kernel, iterations=1)\n",
    "    global_result = cv2.dilate(global_result, kernel, iterations=1)\n",
    "    return global_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDqB6dP7jgef"
   },
   "source": [
    "## Получение данных RSL без train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qzzKhRVejsqT"
   },
   "source": [
    "## Получение данных RSL c train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JFhpMsmAJ2b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def proccess_x(imgs):\n",
    "  x, x_orig = [], []\n",
    "  for img in imgs:\n",
    "    proc = skin_detector(img)\n",
    "    proc = cv2.resize(proc, dsize=(60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "    orig = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    orig = cv2.resize(orig, dsize=(60, 60), interpolation=cv2.INTER_CUBIC)\n",
    "    x.append(proc)\n",
    "    x_orig.append(orig)\n",
    "  x, x_orig = np.array(x) / 255, np.array(x_orig) / 255\n",
    "  x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
    "  x_orig = x_orig.reshape(x_orig.shape[0], x_orig.shape[1], x_orig.shape[2], 1)\n",
    "  return x, x_orig\n",
    "\n",
    "def get_splitted_dataset():\n",
    "  images = np.load('/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/images_E.npy', allow_pickle=True)\n",
    "  labels = np.load('/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/labels_E.npy', allow_pickle=True)\n",
    "  unique_val = np.unique(labels)\n",
    "\n",
    "  label_binrizer = LabelBinarizer()\n",
    "  labels = label_binrizer.fit_transform(labels)\n",
    "\n",
    "  img_t, img_test, y_t, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "  img_train, img_valid, y_train, y_valid = train_test_split(img_t, y_t, test_size=0.2)\n",
    "\n",
    "  x_train, x_orig_train = proccess_x(img_train)\n",
    "  x_test, x_orig_test = proccess_x(img_test)\n",
    "  x_valid, x_orig_valid = proccess_x(img_valid)\n",
    "  return x_train, x_valid, x_test, x_orig_train, x_orig_valid, x_orig_test, y_train,y_valid, y_test, unique_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QiMF7Uf8jvAn"
   },
   "source": [
    "## Получение данных RSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27206,
     "status": "ok",
     "timestamp": 1591619283090,
     "user": {
      "displayName": "Григорий Танцевов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiY72fHLg5AYXzqwOsvSwk6GbJcNY1PkFQ88acKmg=s64",
      "userId": "00673231704768357118"
     },
     "user_tz": -180
    },
    "id": "AP3Bl6fbDyZ7",
    "outputId": "70957c1e-7833-485d-8513-2fc0c8c0c8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8180, 60, 60, 1) (8180, 60, 60, 1)\n",
      "(2045, 60, 60, 1) (2045, 60, 60, 1)\n",
      "(2557, 60, 60, 1) (2557, 60, 60, 1)\n",
      "['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's'\n",
      " 't' 'u' 'v' 'w' 'x' 'y']\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, x_test, x_orig_train, x_orig_valid, x_orig_test, y_train, y_valid, y_test, unique_val = get_splitted_dataset()\n",
    "\n",
    "print(x_train.shape, x_orig_train.shape)\n",
    "print(x_valid.shape, x_orig_valid.shape)\n",
    "print(x_test.shape, x_orig_test.shape)\n",
    "print(unique_val)\n",
    "np.save('/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/classes.npy', unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27200,
     "status": "ok",
     "timestamp": 1591619283091,
     "user": {
      "displayName": "Григорий Танцевов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiY72fHLg5AYXzqwOsvSwk6GbJcNY1PkFQ88acKmg=s64",
      "userId": "00673231704768357118"
     },
     "user_tz": -180
    },
    "id": "GlmJLGK7s6wZ",
    "outputId": "63bd9cda-19d8-4ade-e582-c3f29c39baeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27193,
     "status": "ok",
     "timestamp": 1591619283091,
     "user": {
      "displayName": "Григорий Танцевов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiY72fHLg5AYXzqwOsvSwk6GbJcNY1PkFQ88acKmg=s64",
      "userId": "00673231704768357118"
     },
     "user_tz": -180
    },
    "id": "cG5Zzr9kgBp2",
    "outputId": "27191ed0-a7a8-4644-cc53-0a93b21e0bde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f74873a9630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = x_train[0].copy()\n",
    "x = x.reshape(60, 60)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27496,
     "status": "ok",
     "timestamp": 1591619283401,
     "user": {
      "displayName": "Григорий Танцевов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiY72fHLg5AYXzqwOsvSwk6GbJcNY1PkFQ88acKmg=s64",
      "userId": "00673231704768357118"
     },
     "user_tz": -180
    },
    "id": "_6eqniafheft",
    "outputId": "14cbe346-0e10-425c-c327-6539531707fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f74874d0278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = x_orig_train[0].copy()\n",
    "x = x.reshape(60, 60)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0AWO1W1VG7kb"
   },
   "source": [
    "## CapsNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0L8GQ27G7kc"
   },
   "source": [
    "### Capsule Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAWP4AXWG7kc"
   },
   "source": [
    "Here is the implementation of the necessary layers for the CapsuleNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dB1r6SOqG7kd"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras import initializers, layers\n",
    "\n",
    "class Length(layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss\n",
    "    inputs: shape=[dim_1, ..., dim_{n-1}, dim_n]\n",
    "    output: shape=[dim_1, ..., dim_{n-1}]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask a Tensor with shape=[None, d1, d2] by the max value in axis=1.\n",
    "    Output shape: [None, d2]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # use true label to select target capsule, shape=[batch_size, num_capsule]\n",
    "        if type(inputs) is list:  # true label is provided with shape = [batch_size, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of vectors of capsules\n",
    "            x = inputs\n",
    "            # Enlarge the range of values in x to make max(new_x)=1 and others < 0\n",
    "            x = (x - K.max(x, 1, True)) / K.epsilon() + 1\n",
    "            mask = K.clip(x, 0, 1)  # the max value in x clipped to 1 and other to 0\n",
    "\n",
    "        # masked inputs, shape = [batch_size, dim_vector]\n",
    "        inputs_masked = K.batch_dot(inputs, mask, [1, 1])\n",
    "        return inputs_masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][-1]])\n",
    "        else:\n",
    "            return tuple([None, input_shape[-1]])\n",
    "\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\", The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
    "    :param vectors: some vectors to be squashed, N-dim tensor\n",
    "    :param axis: the axis to squash\n",
    "    :return: a Tensor with same shape as input vectors\n",
    "    \"\"\"\n",
    "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm)\n",
    "    return scale * vectors\n",
    "\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
    "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
    "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_vector] and output shape = \\\n",
    "    [None, num_capsule, dim_vector]. For Dense Layer, input_dim_vector = dim_vector = 1.\n",
    "    \n",
    "    :param num_capsule: number of capsules in this layer\n",
    "    :param dim_vector: dimension of the output vectors of the capsules in this layer\n",
    "    :param num_routings: number of iterations for the routing algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsule, dim_vector, num_routing=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_vector = dim_vector\n",
    "        self.num_routing = num_routing\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_vector]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_vector = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dim_vector],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "        # Coupling coefficient. The redundant dimensions are just to facilitate subsequent matrix calculation.\n",
    "        self.bias = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1],\n",
    "                                    initializer=self.bias_initializer,\n",
    "                                    name='bias',\n",
    "                                    trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_vector]\n",
    "        # Expand dims to [None, input_num_capsule, 1, 1, input_dim_vector]\n",
    "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # Now it has shape = [None, input_num_capsule, num_capsule, 1, input_dim_vector]\n",
    "        inputs_tiled = K.tile(inputs_expand, [1, 1, self.num_capsule, 1, 1])\n",
    "\n",
    "        \"\"\"  \n",
    "        # Compute `inputs * W` by expanding the first dim of W. More time-consuming and need batch_size.\n",
    "        # Now W has shape  = [batch_size, input_num_capsule, num_capsule, input_dim_vector, dim_vector]\n",
    "        w_tiled = K.tile(K.expand_dims(self.W, 0), [self.batch_size, 1, 1, 1, 1])\n",
    "        \n",
    "        # Transformed vectors, inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
    "        inputs_hat = K.batch_dot(inputs_tiled, w_tiled, [4, 3])\n",
    "        \"\"\"\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0. This is faster but requires Tensorflow.\n",
    "        # inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
    "        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n",
    "                             elems=inputs_tiled,\n",
    "                             initializer=K.zeros([self.input_num_capsule, self.num_capsule, 1, self.dim_vector]))\n",
    "        \"\"\"\n",
    "        # Routing algorithm V1. Use tf.while_loop in a dynamic way.\n",
    "        def body(i, b, outputs):\n",
    "        \n",
    "        c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
    "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
    "            b = b + K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
    "            return [i-1, b, outputs]\n",
    "\n",
    "        cond = lambda i, b, inputs_hat: i > 0\n",
    "        loop_vars = [K.constant(self.num_routing), self.bias, K.sum(inputs_hat, 1, keepdims=True)]\n",
    "        _, _, outputs = tf.while_loop(cond, body, loop_vars)\n",
    "        \"\"\"\n",
    "        # Routing algorithm V2. Use iteration. V2 and V1 both work without much difference on performance\n",
    "        assert self.num_routing > 0, 'The num_routing should be > 0.'\n",
    "        for i in range(self.num_routing):\n",
    "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
    "            # outputs.shape=[None, 1, num_capsule, 1, dim_vector]\n",
    "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
    "# last iteration needs not compute bias which will not be passed to the graph any more anyway.\n",
    "            if i != self.num_routing - 1:\n",
    "                # self.bias = K.update_add(self.bias, K.sum(inputs_hat * outputs, [0, -1], keepdims=True))\n",
    "                self.bias += K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
    "            # tf.summary.histogram('BigBee', self.bias)  # for debugging\n",
    "        return K.reshape(outputs, [-1, self.num_capsule, self.dim_vector])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_vector])\n",
    "\n",
    "\n",
    "def PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n",
    "    \"\"\"\n",
    "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
    "    :param dim_vector: the dim of the output vector of capsule\n",
    "    :param n_channels: the number of types of capsules\n",
    "    :return: output tensor, shape=[None, num_capsule, dim_vector]\n",
    "    \"\"\"\n",
    "    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n",
    "    return layers.Lambda(squash)(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fKehFUwG7kg"
   },
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U68Cceg0G7kg"
   },
   "source": [
    "Here we use the layers to build up the model. The model is a bit different from a standard  X→y  model, it is  (X,y)→(y,X)  meaning it attempts to predict the class from the image, and then at the same time, using the same capsule reconstruct the image from the class. The approach appears very cGAN-like where the task of reconstructing better helps the model 'understand' the image data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y4yYvCaG7kh"
   },
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def CapsNet(input_shape, n_class, num_routing):\n",
    "    \"\"\"\n",
    "    A Capsule Network on MNIST.\n",
    "    :param input_shape: data shape, 4d, [None, width, height, channels]\n",
    "    :param n_class: number of classes\n",
    "    :param num_routing: number of routing iterations\n",
    "    :return: A Keras Model with 2 inputs and 2 outputs\n",
    "    \"\"\"\n",
    "    x = layers.Input(shape=input_shape, name=\"image\")\n",
    "\n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv5 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv')(x)\n",
    "\n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_vector]\n",
    "    primarycaps = PrimaryCap(conv5, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps1 = CapsuleLayer(num_capsule=n_class, dim_vector=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n",
    "\n",
    "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='out')(digitcaps1)\n",
    "\n",
    "    # Decoder network.\n",
    "    #y = layers.Input(shape=(n_class,))\n",
    "    #masked = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer.\n",
    "    #x_recon = layers.Dense(512, activation='relu')(masked)\n",
    "    #x_recon = layers.Dense(1024, activation='relu')(x_recon)\n",
    "    #x_recon = layers.Dense(input_shape[0] * input_shape[1], activation='sigmoid')(x_recon)\n",
    "    #x_recon = layers.Reshape(target_shape=input_shape, name='out_recon')(x_recon)\n",
    "\n",
    "    # two-input-two-output keras Model\n",
    "    return models.Model(x, out_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oI-s00jUG7kl"
   },
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9n0GCHbG7ku"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRu3DhcuG7ku"
   },
   "outputs": [],
   "source": [
    "def train(data, n_class, t, epochs=10, epoch_size_frac=1.0, num_routing=3):\n",
    "    print(f'training {t} {num_routing}')\n",
    "    import os\n",
    "    if not os.path.exists(f'/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/{t}/{num_routing}'):\n",
    "        os.makedirs(f'/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/{t}/{num_routing}')\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    model = CapsNet(input_shape=x_train.shape[1:], n_class=n_class, num_routing=num_routing)\n",
    "    # callbacks\n",
    "    log = callbacks.CSVLogger(f'/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/{t}/{num_routing}/log.csv')\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
    "    checkpoint = callbacks.ModelCheckpoint(f'/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/{t}/{num_routing}/best_model.h5', monitor='loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=margin_loss,\n",
    "                  metrics={'out': 'accuracy'})\n",
    "\n",
    "    \"\"\"\n",
    "    # Training without data augmentation:\n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint])\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------Begin: Training with data augmentation -----------------------------------#\n",
    "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "        while 1:\n",
    "            x_batch, y_batch = generator.next()\n",
    "            yield (x_batch, y_batch)\n",
    "\n",
    "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "\n",
    "    model.fit_generator(generator=train_generator(x_train, y_train, 10, 0.),\n",
    "                        steps_per_epoch=int(epoch_size_frac*y_train.shape[0] / 10),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=[x_test, y_test],\n",
    "                        callbacks=[log, lr_decay])\n",
    "    # -----------------------------------End: Training with data augmentation -----------------------------------#\n",
    "\n",
    "    model.save(f'/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/{t}/{num_routing}/trained_model.h5')\n",
    "    print('Trained model saved to \\'trained_model.h5\\'')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "wA9YE52VG7kx",
    "outputId": "ad5f96df-2034-4a0d-d165-c273627d89db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training processed 2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tantsevov/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:949: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:936: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/15\n",
      "817/818 [============================>.] - ETA: 3s - loss: 0.4749 - acc: 0.4902"
     ]
    }
   ],
   "source": [
    "model_proc_2 = train(data=((x_train, y_train), (x_valid, y_valid)), n_class=len(unique_val), num_routing=2, t=\"processed\", epochs=15)\n",
    "model_proc_3 = train(data=((x_train, y_train), (x_valid, y_valid)), n_class=len(unique_val), num_routing=3, t=\"processed\", epochs=15)\n",
    "model_proc_4 = train(data=((x_train, y_train), (x_valid, y_valid)), n_class=len(unique_val), num_routing=4, t=\"processed\", epochs=15)\n",
    "model_proc_5 = train(data=((x_train, y_train), (x_valid, y_valid)), n_class=len(unique_val), num_routing=5, t=\"processed\", epochs=15)\n",
    "model_proc_6 = train(data=((x_train, y_train), (x_valid, y_valid)), n_class=len(unique_val), num_routing=6, t=\"processed\", epochs=15)\n",
    "model_proc_7 = train(data=((x_train, y_train), (x_valid, y_valid)), n_class=len(unique_val), num_routing=7, t=\"processed\", epochs=15)\n",
    "\n",
    "model_orig_2 = train(data=((x_orig_train, y_train), (x_orig_valid, y_valid)), n_class=len(unique_val), num_routing=2, t=\"original\", epochs=30)\n",
    "model_orig_3 = train(data=((x_orig_train, y_train), (x_orig_valid, y_valid)), n_class=len(unique_val), num_routing=3, t=\"original\", epochs=30)\n",
    "model_orig_4 = train(data=((x_orig_train, y_train), (x_orig_valid, y_valid)), n_class=len(unique_val), num_routing=4, t=\"original\", epochs=30)\n",
    "model_orig_5 = train(data=((x_orig_train, y_train), (x_orig_valid, y_valid)), n_class=len(unique_val), num_routing=5, t=\"original\", epochs=30)\n",
    "model_orig_6 = train(data=((x_orig_train, y_train), (x_orig_valid, y_valid)), n_class=len(unique_val), num_routing=6, t=\"original\", epochs=30)\n",
    "model_orig_7 = train(data=((x_orig_train, y_train), (x_orig_valid, y_valid)), n_class=len(unique_val), num_routing=7, t=\"original\", epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tC7w0c3ZG7k0"
   },
   "outputs": [],
   "source": [
    "def test(model, data, t, num):\n",
    "    x_test, y_test = data\n",
    "    y_pred = model.predict(x_test, batch_size=100)\n",
    "    print(y_pred)\n",
    "    b = np.zeros_like(y_pred)\n",
    "    b[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n",
    "    y_pred = np.around(b).astype(np.int)\n",
    "    acc = np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0]\n",
    "    print('-'*50)\n",
    "    print(f'Test acc {t} {num}: {acc}')\n",
    "    with open(f'/home/tantsevov/diploma/data/ASL Finger Spelling Dataset/{t}/{num}/acc','w') as fi:\n",
    "        fi.write(f\"{acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8q8sS0S_G7k2"
   },
   "source": [
    "### Show the results on the hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drKSXKkwG7k3"
   },
   "outputs": [],
   "source": [
    "test(model=model_proc_2, data=(x_test, y_test), t=\"processed\", num=2)\n",
    "test(model=model_proc_3, data=(x_test, y_test), t=\"processed\", num=3)\n",
    "test(model=model_proc_4, data=(x_test, y_test), t=\"processed\", num=4)\n",
    "test(model=model_proc_5, data=(x_test, y_test), t=\"processed\", num=5)\n",
    "test(model=model_proc_6, data=(x_test, y_test), t=\"processed\", num=6)\n",
    "test(model=model_proc_7, data=(x_test, y_test), t=\"processed\", num=7)\n",
    "\n",
    "test(model=model_orig_2, data=(x_orig_test, y_test), t=\"original\", num=2)\n",
    "test(model=model_orig_3, data=(x_orig_test, y_test), t=\"original\", num=3)\n",
    "test(model=model_orig_4, data=(x_orig_test, y_test), t=\"original\", num=4)\n",
    "test(model=model_orig_5, data=(x_orig_test, y_test), t=\"original\", num=5)\n",
    "test(model=model_orig_6, data=(x_orig_test, y_test), t=\"original\", num=6)\n",
    "test(model=model_orig_7, data=(x_orig_test, y_test), t=\"original\", num=7)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "asl-gestures.ipynb",
   "provenance": [
    {
     "file_id": "1a1D9paw8i8DjK8mxWbydLKw7tRklumwd",
     "timestamp": 1591282822192
    },
    {
     "file_id": "1MzkxUfjmRfaIjK32H7HhDOcKELExXzz_",
     "timestamp": 1588077201828
    },
    {
     "file_id": "1ZZRbpEcRT5W5IJVBglXNTqvxEhGH7ZqH",
     "timestamp": 1587537322408
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
